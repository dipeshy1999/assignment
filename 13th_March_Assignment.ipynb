{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3b8c9a-d33a-4da4-ab20-89e11d3c9ffa",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8ba1f-6771-49cb-9a89-36f6e6bf96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA (Analysis of Variance) is a statistical technique used to compare the means of three or more groups. It relies on several assumptions \n",
    "# to ensure the validity of the results. Let's discuss these assumptions and provide examples of violations that could affect the validity of \\\n",
    "# the ANOVA results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b39f7-db55-4495-92ce-58eabc224215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Independence: The observations within each group must be independent of each other. Violations occur when there is dependence or correlation \n",
    "# between the observations. For example, if the measurements taken from individuals within the same family are not independent, ANOVA assumptions\n",
    "# are violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e821a-a102-4839-9b84-4d5727053bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normality: The data within each group should follow a normal distribution. This assumption is most critical when the sample sizes are small. \n",
    "# Violations can occur when the data significantly deviates from normality. For instance, if the data is heavily skewed or has extreme outliers, \n",
    "# it may violate the normality assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e815a75-787a-4f67-ad96-09a31459f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Homogeneity of variance: The variances of the different groups being compared should be approximately equal. Violations arise when the \n",
    "# variability across groups is significantly different. For example, if one group has a much larger variance compared to the others, the assumption \n",
    "# of homogeneity of variance is violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07139478-799e-4fdd-854f-1912ed71da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Independence of errors: The errors or residuals (the differences between observed values and predicted values) should be independent of \n",
    "# each other. Violations occur when there is a pattern or correlation among the residuals. For instance, if the residuals systematically increase \n",
    "# or decrease across the levels of the independent variable, the assumption of independence of errors is violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f428ae1-4017-4ca7-a613-450ad87a90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of violations and their impact on ANOVA results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88321e40-3665-44ce-9877-c414cde91c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Non-independence: If participants in a study are related (e.g., siblings), and their responses are not independent, the assumption of \n",
    "# independence is violated. The violation can lead to inflated or deflated F-statistics, which can impact the validity of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce34b7-1c56-42ff-8004-a3a9a73e29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Non-normality: If the data within each group significantly deviates from a normal distribution, the assumption of normality is violated. \n",
    "# This violation can affect the accuracy of p-values and confidence intervals. In such cases, non-parametric alternatives or transformations of \n",
    "# the data may be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb04cc-5926-41aa-8c3e-5e071be6e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Heterogeneity of variance: When the variability across groups is significantly different, violating the assumption of homogeneity of variance, \n",
    "# the F-statistic may be biased. If the group with larger variance also has larger means, ANOVA may erroneously identify a significant difference \n",
    "# between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dd4e7-d79d-4227-9d79-30f29892f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dependence of errors: If there is a pattern or correlation among the residuals, violating the assumption of independence of errors, the \n",
    "# standard errors of the estimates may be incorrect. This can lead to inaccurate hypothesis tests and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65c032-e4b6-4ed6-93db-492341e8b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important to note that while violations of these assumptions can impact the validity of ANOVA results, the impact and severity of \n",
    "# violations depend on the specific context and the extent of the violation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e6638-6775-4895-8bd8-0764f591d36d",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9869ee-20fd-45ee-a05a-7c75e4708fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three types of ANOVA are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2ce98-5fa8-47b9-b2eb-9e7c7214b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.One-way ANOVA: One-way ANOVA is used when you have one categorical independent variable (also known as a factor) with three or more levels \n",
    "# and a continuous dependent variable. It is used to determine if there are any significant differences between the means of the groups defined \n",
    "# by the levels of the independent variable. For example, you might use one-way ANOVA to compare the average scores of students in three different \n",
    "# teaching methods (e.g., lecture, discussion, and online) to determine if there are any significant differences in learning outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc37532-e9e4-4088-9c50-98f922b52d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Two-way ANOVA: Two-way ANOVA is used when you have two independent variables (factors) and a continuous dependent variable. Each independent \n",
    "# variable has two or more levels, and the interaction between the two independent variables is of interest. Two-way ANOVA allows you to analyze \n",
    "# the main effects of each independent variable as well as their interaction effect on the dependent variable. For example, you might use two-way \n",
    "# ANOVA to examine the effects of both gender (male vs. female) and treatment type (drug A vs. drug B) on blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4775a8-f05c-4f8b-b81a-ed3410fbdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Mixed-effects ANOVA: Mixed-effects ANOVA, also known as repeated-measures ANOVA, is used when you have one or more within-subject factors \n",
    "# (repeated measures) and one or more between-subject factors. It is appropriate when you have a mix of both within-subject and between-subject v\n",
    "# ariables. Mixed-effects ANOVA allows you to examine the effects of each factor individually as well as their interaction effect. This type of \n",
    "# ANOVA is commonly used in longitudinal or experimental designs where measurements are taken at multiple time points or under different conditions.\n",
    "# For example, you might use mixed-effects ANOVA to analyze the effects of time (within-subject factor) and treatment group (between-subject factor) \n",
    "# on the pain levels of patients over a period of several weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfe911-6c5f-4696-85ac-9a7e779b78c6",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be1021-3b96-4fe4-835b-b77e6c1da50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The partitioning of variance in ANOVA refers to the decomposition of the total variability observed in a dataset into different sources or \n",
    "# components. Understanding this concept is essential because it helps us identify the contributions of various factors and their interactions\n",
    "# to the overall variation in the data. It allows us to quantify the proportion of variability explained by different sources and determine if \n",
    "# these sources are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356daf0-9748-4d66-bb87-bd3a46ae75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ANOVA, the total variability observed in the data is divided into two main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554a52f-1a94-41c3-af99-96ec9794537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Between-group variability: This component represents the variability among the group means or levels of the independent variable. \n",
    "# It reflects the differences between the groups being compared. If the between-group variability is large relative to the within-group \n",
    "# variability, it suggests that there are significant differences between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7a6f2-c44d-447a-9070-c1879e8e32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-group variability: This component represents the variability within each group or level of the independent variable. It reflects the \n",
    "# individual differences or random variation within each group. The within-group variability serves as the baseline or reference level of \n",
    "# variability against which the between-group variability is compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe11943-240f-4be6-bcfd-a86f96b794c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By partitioning the total variability into these two components, ANOVA helps us evaluate the significance of group differences and determine \n",
    "# whether the observed differences are likely due to the effects of the independent variable or simply due to random variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3af097-dac2-479b-a68e-69b939f9f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the partitioning of variance is important for several reasons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d3c72-ae0a-4863-ad42-1408572e6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Hypothesis testing: ANOVA uses the partitioning of variance to assess the statistical significance of group differences. By comparing the \n",
    "# ratio of between-group variability to within-group variability (F-ratio), ANOVA helps determine if the observed differences are significant \n",
    "# or likely to have occurred by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5d589-53e2-4d07-849b-e09ec3f01849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect size estimation: The partitioning of variance allows us to quantify the proportion of variability explained by the independent \n",
    "# variable(s) and their interactions. This information is crucial for assessing the practical significance or importance of the observed \n",
    "# effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2544dd6-fcd5-4f9b-a2d6-06f992ac2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation: The partitioning of variance helps evaluate the goodness-of-fit of the ANOVA model. It allows us to determine how well \n",
    "# the model accounts for the observed variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be46f32-0468-4fca-b085-888cbf6ecbbe",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23d32f5-1929-43d1-a493-fc1bba873754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 230.0\n",
      "Explained sum of squares (SSE): 90.0\n",
      "Residual sum of squares (SSR): 140.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [2, 4, 6, 8, 10]\n",
    "group3 = [3, 6, 9, 12, 15]\n",
    "\n",
    "# Combine the groups into a single list\n",
    "data = group1 + group2 + group3\n",
    "\n",
    "# Compute the overall mean\n",
    "overall_mean = sum(data) / len(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = sum((x - overall_mean) ** 2 for x in data)\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = [sum(group) / len(group) for group in [group1, group2, group3]]\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = sum(len(group) * (mean - overall_mean) ** 2 for group, mean in zip([group1, group2, group3], group_means))\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total sum of squares (SST):\", sst)\n",
    "print(\"Explained sum of squares (SSE):\", sse)\n",
    "print(\"Residual sum of squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96828a3-01be-4a3b-9851-a14cad46c3d3",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6f9a12-dbcf-41cf-9196-0967af8a714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect A: 28.900000000000002\n",
      "Main effect B: 12.50000000000001\n",
      "Interaction effect: 1.9721522630525295e-31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 1, 2, 2, 3, 3, 4, 4],\n",
    "    'B': [1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    'Y': [3, 5, 4, 7, 6, 9, 8, 10]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Y ~ A + B + A:B', data=data).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_A = anova_table['sum_sq']['A']\n",
    "main_effect_B = anova_table['sum_sq']['B']\n",
    "interaction_effect = anova_table['sum_sq']['A:B']\n",
    "\n",
    "print(\"Main effect A:\", main_effect_A)\n",
    "print(\"Main effect B:\", main_effect_B)\n",
    "print(\"Interaction effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed271148-0174-496f-9817-44983b2706a8",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229bae7-be0c-48d8-9698-1626ffd3f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the given scenario, you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. Based on these results, we \n",
    "# can draw the following conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9351f4-21bc-46e4-ab69-66abb8e61e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Differences between groups: The obtained F-statistic of 5.23 indicates that there are significant differences between the groups. \n",
    "# The F-statistic measures the ratio of the between-group variability to the within-group variability. A larger F-value suggests a greater \n",
    "# difference between the group means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f151a-1da4-47db-b068-c9fd56fe8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Statistical significance: The p-value of 0.02 indicates that the observed differences between the groups are statistically significant. \n",
    "# The p-value represents the probability of obtaining the observed data or more extreme data if the null hypothesis (no group differences) \n",
    "# were true. A p-value less than the chosen significance level (e.g., 0.05) suggests that the differences between the groups are unlikely to \n",
    "# have occurred by chance alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6ad53-45d2-4f2c-b4b3-5e8365bd8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting these results, we can conclude that there are significant differences between the groups based on the one-way ANOVA. \n",
    "# This implies that at least one group mean differs significantly from the means of the other groups. However, it does not provide specific \n",
    "# information about which group means are different from each other. To identify the specific group differences, further post hoc tests or \n",
    "# pairwise comparisons may be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdc4a7-2740-44ff-ab44-a8959c7ac964",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ddfa3e-0f1a-4ff9-b2e1-dfd4fd7f36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data in a repeated measures ANOVA requires careful consideration as it can impact the validity and reliability of the analysis. \n",
    "# Here are some common approaches to handle missing data in a repeated measures ANOVA and their potential consequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deac730-7c8c-4739-a913-1502f6c52960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Complete Case Analysis (Listwise deletion): This approach involves excluding any cases with missing data from the analysis. \n",
    "# The consequence of this method is a reduction in sample size, potentially leading to loss of statistical power and potentially biased \n",
    "# results if the missingness is related to the variables of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eeffab-d2b0-44f6-93f6-f1719e6556ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pairwise Deletion: This approach involves including all available data for each pairwise comparison, even if some cases have missing data \n",
    "#for certain variables. The consequence of this method is that different comparisons may have different sample sizes, potentially affecting \n",
    "# the precision and power of the analysis. However, this method utilizes more data compared to complete case analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550db4df-4d43-42f4-9183-7d9d322091a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Mean Substitution: This approach involves replacing missing values with the mean value of the corresponding variable. The consequence of \n",
    "#this method is that it may underestimate the variance of the data, leading to biased estimates of the population parameters and potentially \n",
    "# distorting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad337d-d115-4eb2-82c8-9a4ed1112091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Last Observation Carried Forward (LOCF): This approach involves replacing missing values with the last observed value from the same \n",
    "# individual. The consequence of this method is that it assumes the missing data is consistent with the last observed value, which may not\n",
    "# be valid in cases where the missingness is related to the variables being measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf5b52-179f-4482-8ff1-0254ac143ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Multiple Imputation: This approach involves creating multiple plausible imputed values for each missing data point based on the observed \n",
    "# data and a statistical model. The consequence of this method is that it accounts for the uncertainty associated with the missing data, provides \n",
    "# more valid and efficient estimates, and can lead to more accurate statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82afea1-1474-410f-be5f-5224e8a653ae",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52592c-32f9-4469-ab04-9023dee471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tukey's Honestly Significant Difference (HSD) Test: Tukey's HSD test compares all possible pairs of group means and provides a simultaneous \n",
    "# confidence interval for each pairwise difference. It controls for the family-wise error rate, making it suitable when conducting multiple \n",
    "# comparisons. Tukey's HSD is generally recommended when the sample sizes are equal or similar across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506add2d-87f0-4cd9-9713-b54ed7efd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bonferroni Correction: The Bonferroni correction is a conservative approach that adjusts the significance level for each pairwise comparison. \n",
    "# The corrected significance level is divided by the number of comparisons being made. This method is appropriate when conducting a large number \n",
    "# of pairwise comparisons, as it controls the family-wise error rate but may have reduced power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c242b-520c-461b-b612-1bba54410ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scheffé's Test: Scheffé's test is a conservative post-hoc test that compares all possible pairwise differences while controlling the \n",
    "# family-wise error rate. It is more robust but less powerful compared to other post-hoc tests. Scheffé's test is useful when the sample \n",
    "# sizes are unequal or the assumptions for other post-hoc tests are violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe0e10-0c2a-45da-8969-5059327880f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dunnett's Test: Dunnett's test is used when comparing multiple treatment groups to a control group. It controls the overall type I error \n",
    "# rate when conducting multiple comparisons against a single control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b7c96-6aa5-4da3-bc04-aa4a810d01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Games-Howell Test: The Games-Howell test is a robust post-hoc test that does not assume equal variances or equal sample sizes across groups. \n",
    "# It is useful when the assumption of homogeneity of variances is violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0a723-237a-45c9-bdb3-8c6fd9f2f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example scenario: Let's say you conducted a study comparing the effectiveness of four different teaching methods (A, B, C, and D) on student \n",
    "# performance. You performed a one-way ANOVA and found a significant overall effect (p < 0.05). Now, you want to determine which specific pairs \n",
    "# of teaching methods differ significantly from each other. In this situation, you would apply a post-hoc test, such as Tukey's HSD or \n",
    "# Scheffé's test, to compare all possible pairs of teaching methods and identify significant differences between them. These post-hoc tests \n",
    "# would provide specific information about which teaching methods yield significantly different outcomes, allowing for a more nuanced \n",
    "# interpretation of the study results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970ead2-849c-4d8e-aa8f-5d5dbf71d484",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d791593-e271-4fdb-a90c-eea55c70bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 195.83023803912337\n",
      "p-value: 3.5169279849919386e-42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Weight loss data for each diet\n",
    "diet_A = np.array([2.1, 1.8, 2.5, 1.9, 2.3, 2.0, 1.7, 1.5, 1.8, 1.9,\n",
    "                   2.1, 2.4, 1.8, 2.2, 2.5, 2.3, 2.0, 1.9, 2.1, 1.8,\n",
    "                   2.5, 1.9, 2.3, 2.0, 1.7, 1.5, 1.8, 1.9, 2.1, 2.4,\n",
    "                   1.8, 2.2, 2.5, 2.3, 2.0, 1.9, 2.1, 1.8, 2.5, 1.9,\n",
    "                   2.3, 2.0, 1.7, 1.5, 1.8, 1.9, 2.1, 2.4, 1.8, 2.2])\n",
    "\n",
    "diet_B = np.array([2.4, 2.1, 2.7, 2.6, 2.9, 2.5, 2.3, 2.2, 2.1, 2.4,\n",
    "                   2.0, 2.6, 2.3, 2.1, 2.7, 2.6, 2.9, 2.5, 2.3, 2.2,\n",
    "                   2.1, 2.4, 2.0, 2.6, 2.3, 2.1, 2.7, 2.6, 2.9, 2.5,\n",
    "                   2.3, 2.2, 2.1, 2.4, 2.0, 2.6, 2.3, 2.1, 2.7, 2.6,\n",
    "                   2.9, 2.5, 2.3, 2.2, 2.1, 2.4, 2.0, 2.6, 2.3, 2.1])\n",
    "\n",
    "diet_C = np.array([3.0, 2.7, 3.2, 2.8, 3.1, 2.9, 3.2, 3.0, 2.8, 3.1,\n",
    "                   2.7, 3.2, 2.9, 3.0, 2.8, 3.1, 2.9, 3.2, 3.0, 2.8,\n",
    "                   3.1, 2.7, 3.2, 2.9, 3.0, 2.8, 3.1, 2.9, 3.2, 3.0,\n",
    "                   2.8, 3.1, 2.7, 3.2, 2.9, 3.0, 2.8, 3.1, 2.9, 3.2,\n",
    "                   3.0, 2.8, 3.1, 2.7, 3.2, 2.9, 3.0, 2.8, 3.1, 2.9])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dc0c9d-8ec0-4350-b238-47189ab81fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0: There is no significant difference between the 3 diets.\n",
    "# H1: There is significant difference between the 3 diets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282bdc4a-e76f-423f-bd6c-0be801bb2ae4",
   "metadata": {},
   "source": [
    "# Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6c2a8c-08b8-4bc4-96c6-c3674a860d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -4.754695943505281\n",
      "p-value: 3.819135262679478e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate random test scores for the control and experimental groups\n",
    "np.random.seed(42)\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc tests (e.g., Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    # Combine the data from both groups\n",
    "    combined_data = np.concatenate([control_group, experimental_group])\n",
    "\n",
    "    # Create group labels (0 for control, 1 for experimental)\n",
    "    group_labels = np.concatenate([np.zeros_like(control_group), np.ones_like(experimental_group)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc4822-fc1b-4735-b08f-d1ea615b4bb9",
   "metadata": {},
   "source": [
    "# Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4efa1918-13ed-4d41-8d77-0d13964e71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            df        sum_sq       mean_sq             F    PR(>F)\n",
      "Store      2.0  6.276177e-27  3.138089e-27  5.150825e-01  0.600158\n",
      "C(Day)    29.0  2.510900e+03  8.658276e+01  1.421160e+28  0.000000\n",
      "Residual  58.0  3.533592e-25  6.092400e-27           NaN       NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     A      B      0.0   1.0 -3.3075 3.3075  False\n",
      "     A      C      0.0   1.0 -3.3075 3.3075  False\n",
      "     B      C      0.0   1.0 -3.3075 3.3075  False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Day': list(range(1, 31)) * 3,\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [50, 55, 60, 58, 57, 54, 52, 55, 59, 60, 55, 53, 54, 58, 56, 55, 53, 52,\n",
    "              45, 48, 46, 44, 47, 50, 45, 43, 42, 44, 49, 50] * 3\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform the repeated measures ANOVA\n",
    "model = ols('Sales ~ Store + C(Day)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Perform the post-hoc test\n",
    "posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "print(posthoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfa525-8776-4aff-94a1-109a07088f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
